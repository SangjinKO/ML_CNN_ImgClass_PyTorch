{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "HW4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwSblWSIX-qM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "current_path = ''\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz2OOgcCy1F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function for computing accuracy\n",
        "def get_acc(pred, y):\n",
        "    pred = pred.float()\n",
        "    y = y.float()\n",
        "    return (y==pred).sum().float()/y.size(0)*100."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-7GdjG5y1GG",
        "colab_type": "code",
        "outputId": "4a0b55fe-fc5e-42d7-fac6-0d3c7b34b04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Preprocessing steps on the training/testing data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# download the dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root=current_path + '/data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root=current_path + '/data', train=False, download=True, transform=transform_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RKgYXUty1GT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_acc(model, loader):\n",
        "    ys = []\n",
        "    y_preds = []\n",
        "    for x, y in loader:\n",
        "        ys.append(y)\n",
        "        y_preds.append(torch.argmax(model(x), dim=1))\n",
        "    y = torch.cat(ys, dim=0)\n",
        "    y_pred = torch.cat(y_preds, dim=0)\n",
        "    print((y == y_pred).sum())\n",
        "    return get_acc(y_pred, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1ayhXliy1Gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "class CNNClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, D_in, D_out):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "       \n",
        "        # set dim. (constants)\n",
        "        f_size = 5 #convolution filter size (kernel size)\n",
        "        # p_size = 2  #max pooling filter size\n",
        "        p_stride = 2 #conv/pooling stride\n",
        "        p_padding = 1 #conv/pooling padding\n",
        "        n_filter = 8 #output_size = x_h - n_filter + 1\n",
        "        # fc_size = 16 * 8 * 8 #w/o pooling\n",
        "        fc_size = 512 \n",
        "\n",
        "        # 1) Conv\n",
        "        self.conv_1 = nn.Conv2d(D_in, n_filter, f_size, stride=p_stride, padding=p_padding) \n",
        "        self.conv_2 = nn.Conv2d(8, 16, 3, stride=p_stride, padding=p_padding) # hyperparameters are calculated by the hyperparameters in the previous layer (CONV)\n",
        "        self.conv_3 = nn.Conv2d(16, 32, 3, stride=p_stride, padding=p_padding) # hyperparameters are calculated by the hyperparameters in the previous layer (CONV)\n",
        "        self.conv_4 = nn.Conv2d(32, 64, 3, stride=1) # hyperparameters are calculated by the hyperparameters in the previous layer (CONV)\n",
        "        self.conv_5 = nn.Conv2d(64, 128, 3, stride=1, padding=p_padding) # hyperparameters are calculated by the hyperparameters in the previous layer (CONV)\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "\n",
        "        # 2) Relu\n",
        "        self.relu = nn.ReLU()  \n",
        "\n",
        "        # 3) Pool\n",
        "        # self.pool = nn.MaxPool2d(kernel_size = p_size, stride=1)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
        "\n",
        "        # OPT: Batchnorm\n",
        "        self.batch = nn.BatchNorm1d (fc_size)\n",
        "\n",
        "        # 4) Linear \n",
        "        self.fc = nn.Linear(fc_size, D_out)          \n",
        "\n",
        "        # Simple version 1~4 w/o pooling\n",
        "        # self.cnn= nn.Sequential(\n",
        "        #                     nn.Conv2d(3, 8, kernel_size=5, stride=2, padding=1),\n",
        "        #                     nn.ReLU(),\n",
        "        #                     nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
        "        #                     nn.ReLU()\n",
        "        #             )\n",
        "        # self.fc = nn.Linear(16 * 8 * 8, 10)       \n",
        "        \n",
        "        \n",
        "    def forward(self, x):       \n",
        "        # size of x: torch.Size([64, 3, 32, 32])\n",
        "        \n",
        "        #layer 1 Conv\n",
        "        l1 = self.conv_1(x)\n",
        "        # print(\"layer1-Conv:\", l1.size()) \n",
        "\n",
        "        #layer 2 ReLU\n",
        "        l2 = self.relu(l1)\n",
        "        # print(\"layer2-ReLU:\", l2.size()) \n",
        "\n",
        "        #layer 3 Conv\n",
        "        l3 = self.conv_2(l2)\n",
        "        # print(\"layer3-Conv:\", l3.size()) \n",
        "\n",
        "        #layer 4 ReLU\n",
        "        l4 = self.relu(l3)\n",
        "        # print(\"layer4-ReLU:\", l4.size()) \n",
        "\n",
        "        #layer 5 Conv\n",
        "        l5 = self.conv_3(l4)\n",
        "        # print(\"layer5-Conv:\", l5.size()) \n",
        "\n",
        "        #layer 6 ReLU\n",
        "        l6 = self.relu(l5)\n",
        "        # print(\"layer6-ReLU:\", l6.size()) \n",
        "\n",
        "        #layer 7 Conv\n",
        "        l7 = self.conv_4(l6)\n",
        "        # print(\"layer7-Conv:\", l7.size()) \n",
        "\n",
        "        #layer 8 ReLU\n",
        "        l8 = self.relu(l7)\n",
        "        # print(\"layer8-ReLU:\", l8.size()) \n",
        "\n",
        "        #layer 9 Conv\n",
        "        l9 = self.conv_5(l8)\n",
        "        # print(\"layer7-Conv:\", l7.size()) \n",
        "\n",
        "        #layer 10 ReLU\n",
        "        l_pool = self.relu(l9)\n",
        "        # print(\"layer8-ReLU:\", l8.size()) \n",
        "\n",
        "        #layer Pooling\n",
        "        # l_pool = self.pool(l_conv)\n",
        "        # print(\"layer-Pooling:\", l_pool.size())       \n",
        "\n",
        "        #layer fully-connected (linear) + OPT: Apply BatchNorm\n",
        "        # flatten the output of your convolutional networks with view()\n",
        "        l_pool = l_pool.view(l_pool.size(0),-1)\n",
        "        # print(\"fully-input:\", l7.size()) \n",
        "        l_bat = self.batch (l_pool)\n",
        "        y_pred = self.fc(l_bat)\n",
        "        # print(\"layer-fc:\", y_pred.size()) \n",
        "\n",
        "        return y_pred\n",
        "        \n",
        "        ## Simple version 1~4 w/o pooling\n",
        "        # batch_size = x.size(0)\n",
        "        # return self.fc(self.cnn(x).view(batch_size, -1))\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mZ3iGNzMn7r",
        "colab_type": "code",
        "outputId": "2649b8e2-5233-46e3-e42c-0c023410f8a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "# Set hyperparameters\n",
        "epoch =15\n",
        "lr = 1e-3\n",
        "n_input = 3072\n",
        "n_classes = 10\n",
        "batch_size = 64\n",
        "\n",
        "# Load dataset\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "#set dim.\n",
        "# x (N, C,H, W) # torch.Size([64, 3, 32, 32])\n",
        "D_in = 3 #input channel\n",
        "D_out = n_classes #number of classes\n",
        "\n",
        "#init.\n",
        "model = CNNClassifier(D_in, D_out)\n",
        "model.train() ## Set the module in a training mode\n",
        "\n",
        "# Set optimizer\n",
        "# optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=lr, eps=1e-2)\n",
        "# optim = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "# optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True)\n",
        "# optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "# optim = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
        "# optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Set loss function\n",
        "criterion = nn.CrossEntropyLoss() #torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
        "# criterion = nn.BCELoss()\n",
        "\n",
        "#train\n",
        "for e in range(epoch):\n",
        "  loss_epoch = 0\n",
        "  \n",
        "  for x, y in train_loader:\n",
        "    optim.zero_grad()   \n",
        "    y_pred = model(x)\n",
        "\n",
        "    loss = criterion(y_pred, y)\n",
        "\n",
        "    #update\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    loss_epoch += loss.item()\n",
        "\n",
        "  print(f'Epcoh {e}: {loss_epoch}')\n",
        "\n",
        "#evaluation (train/test accuracies)\n",
        "model.eval()\n",
        "train_acc = get_model_acc(model, train_loader)\n",
        "test_acc = get_model_acc(model, test_loader)\n",
        "print(f'Training accuracy: {train_acc}, Testing accuracy: {test_acc}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epcoh 0: 1224.3110374212265\n",
            "Epcoh 1: 1026.344265460968\n",
            "Epcoh 2: 934.7565296888351\n",
            "Epcoh 3: 866.5753960609436\n",
            "Epcoh 4: 814.7807305455208\n",
            "Epcoh 5: 767.5877351164818\n",
            "Epcoh 6: 729.54525411129\n",
            "Epcoh 7: 694.6232128739357\n",
            "Epcoh 8: 660.1824998259544\n",
            "Epcoh 9: 630.0203550457954\n",
            "Epcoh 10: 603.7329992055893\n",
            "Epcoh 11: 575.5309460163116\n",
            "Epcoh 12: 555.0155566036701\n",
            "Epcoh 13: 537.4864779114723\n",
            "Epcoh 14: 513.6218617260456\n",
            "tensor(40248)\n",
            "tensor(6548)\n",
            "Training accuracy: 80.49600219726562, Testing accuracy: 65.4800033569336\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}